{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "字母图片_cnn_分类.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/CSTOMJason/Cnn_cat_and_people_classification/blob/master/%E5%AD%97%E6%AF%8D%E5%9B%BE%E7%89%87_cnn_%E5%88%86%E7%B1%BB.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "F8JULVhWpCoR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "4b529aca-d7b4-41d5-f76d-c0893bebdacc"
      },
      "cell_type": "code",
      "source": [
        "!pip install imageio\n",
        "# These are all the modules we'll be using later. Make sure you can import them\n",
        "# before proceeding further.\n",
        "from __future__ import print_function\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import tarfile\n",
        "from IPython.display import display, Image\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "from six.moves import cPickle as pickle\n",
        "\n",
        "# Config the matplotlib backend as plotting inline in IPython\n",
        "%matplotlib inline"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.14.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->imageio) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g8kyNOHtpXyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "fd11dc7d-a812-47bb-8528-b32d97ed4b67"
      },
      "cell_type": "code",
      "source": [
        "#下载数据集\n",
        "url = 'https://commondatastorage.googleapis.com/books1000/'\n",
        "last_percent_reported = None\n",
        "data_root = '.' # Change me to store data elsewhere\n",
        "\n",
        "def download_progress_hook(count, blockSize, totalSize):\n",
        "  \"\"\"A hook to report the progress of a download. This is mostly intended for users with\n",
        "  slow internet connections. Reports every 5% change in download progress.\n",
        "  \"\"\"\n",
        "  global last_percent_reported\n",
        "  percent = int(count * blockSize * 100 / totalSize)\n",
        "\n",
        "  if last_percent_reported != percent:\n",
        "    if percent % 5 == 0:\n",
        "      sys.stdout.write(\"%s%%\" % percent)\n",
        "      sys.stdout.flush()\n",
        "    else:\n",
        "      sys.stdout.write(\".\")\n",
        "      sys.stdout.flush()\n",
        "      \n",
        "    last_percent_reported = percent\n",
        "        \n",
        "def maybe_download(filename, expected_bytes, force=False):\n",
        "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
        "  dest_filename = os.path.join(data_root, filename)\n",
        "  if force or not os.path.exists(dest_filename):\n",
        "    print('Attempting to download:', filename) \n",
        "    filename, _ = urlretrieve(url + filename, dest_filename, reporthook=download_progress_hook)\n",
        "    print('\\nDownload Complete!')\n",
        "  statinfo = os.stat(dest_filename)\n",
        "  if statinfo.st_size == expected_bytes:\n",
        "    print('Found and verified', dest_filename)\n",
        "  else:\n",
        "    raise Exception(\n",
        "      'Failed to verify ' + dest_filename + '. Can you get to it with a browser?')\n",
        "  return dest_filename\n",
        "\n",
        "train_filename = maybe_download('notMNIST_large.tar.gz', 247336696)\n",
        "test_filename = maybe_download('notMNIST_small.tar.gz', 8458043)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found and verified ./notMNIST_large.tar.gz\n",
            "Found and verified ./notMNIST_small.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y-OwNC8ZpclH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "936dedb8-c619-486f-bfe7-a4216836ed5e"
      },
      "cell_type": "code",
      "source": [
        "#解压数据集并读取数据到对应的文件夹中\n",
        "num_classes = 10\n",
        "np.random.seed(133)\n",
        "\n",
        "def maybe_extract(filename, force=False):\n",
        "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
        "  if os.path.isdir(root) and not force:\n",
        "    # You may override by setting force=True.\n",
        "    print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
        "  else:\n",
        "    print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
        "    tar = tarfile.open(filename)\n",
        "    sys.stdout.flush()\n",
        "    tar.extractall(data_root)\n",
        "    tar.close()\n",
        "  data_folders = [\n",
        "    os.path.join(root, d) for d in sorted(os.listdir(root))\n",
        "    if os.path.isdir(os.path.join(root, d))]\n",
        "  if len(data_folders) != num_classes:\n",
        "    raise Exception(\n",
        "      'Expected %d folders, one per class. Found %d instead.' % (\n",
        "        num_classes, len(data_folders)))\n",
        "  print(data_folders)\n",
        "  return data_folders\n",
        "  \n",
        "train_folders = maybe_extract(train_filename)\n",
        "test_folders = maybe_extract(test_filename)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./notMNIST_large already present - Skipping extraction of ./notMNIST_large.tar.gz.\n",
            "['./notMNIST_large/A', './notMNIST_large/B', './notMNIST_large/C', './notMNIST_large/D', './notMNIST_large/E', './notMNIST_large/F', './notMNIST_large/G', './notMNIST_large/H', './notMNIST_large/I', './notMNIST_large/J']\n",
            "./notMNIST_small already present - Skipping extraction of ./notMNIST_small.tar.gz.\n",
            "['./notMNIST_small/A', './notMNIST_small/B', './notMNIST_small/C', './notMNIST_small/D', './notMNIST_small/E', './notMNIST_small/F', './notMNIST_small/G', './notMNIST_small/H', './notMNIST_small/I', './notMNIST_small/J']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rF4B-6vLpudn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "080d75b8-e95c-4d7d-853a-5345379c3d7e"
      },
      "cell_type": "code",
      "source": [
        "image_size = 28  # Pixel width and height.\n",
        "pixel_depth = 255.0  # Number of levels per pixel.\n",
        "\n",
        "def load_letter(folder, min_num_images):\n",
        "  \"\"\"Load the data for a single letter label.\"\"\"\n",
        "  image_files = os.listdir(folder)\n",
        "  dataset = np.ndarray(shape=(len(image_files), image_size, image_size),\n",
        "                         dtype=np.float32)\n",
        "  print(folder)\n",
        "  num_images = 0\n",
        "  for image in image_files:\n",
        "    image_file = os.path.join(folder, image)\n",
        "    try:\n",
        "      image_data = (imageio.imread(image_file).astype(float) - \n",
        "                    pixel_depth / 2) / pixel_depth\n",
        "      if image_data.shape != (image_size, image_size):\n",
        "        raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
        "      dataset[num_images, :, :] = image_data\n",
        "      num_images = num_images + 1\n",
        "    except (IOError, ValueError) as e:\n",
        "      print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
        "    \n",
        "  dataset = dataset[0:num_images, :, :]\n",
        "  if num_images < min_num_images:\n",
        "    raise Exception('Many fewer images than expected: %d < %d' %\n",
        "                    (num_images, min_num_images))\n",
        "    \n",
        "  print('Full dataset tensor:', dataset.shape)\n",
        "  print('Mean:', np.mean(dataset))\n",
        "  print('Standard deviation:', np.std(dataset))\n",
        "  return dataset\n",
        "        \n",
        "def maybe_pickle(data_folders, min_num_images_per_class, force=False):\n",
        "  dataset_names = []\n",
        "  for folder in data_folders:\n",
        "    set_filename = folder + '.pickle'\n",
        "    dataset_names.append(set_filename)\n",
        "    if os.path.exists(set_filename) and not force:\n",
        "      # You may override by setting force=True.\n",
        "      print('%s already present - Skipping pickling.' % set_filename)\n",
        "    else:\n",
        "      print('Pickling %s.' % set_filename)\n",
        "      dataset = load_letter(folder, min_num_images_per_class)\n",
        "      try:\n",
        "        with open(set_filename, 'wb') as f:\n",
        "          pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
        "      except Exception as e:\n",
        "        print('Unable to save data to', set_filename, ':', e)\n",
        "  \n",
        "  return dataset_names\n",
        "\n",
        "train_datasets = maybe_pickle(train_folders, 45000)\n",
        "test_datasets = maybe_pickle(test_folders, 1800)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./notMNIST_large/A.pickle already present - Skipping pickling.\n",
            "./notMNIST_large/B.pickle already present - Skipping pickling.\n",
            "./notMNIST_large/C.pickle already present - Skipping pickling.\n",
            "./notMNIST_large/D.pickle already present - Skipping pickling.\n",
            "./notMNIST_large/E.pickle already present - Skipping pickling.\n",
            "./notMNIST_large/F.pickle already present - Skipping pickling.\n",
            "./notMNIST_large/G.pickle already present - Skipping pickling.\n",
            "./notMNIST_large/H.pickle already present - Skipping pickling.\n",
            "./notMNIST_large/I.pickle already present - Skipping pickling.\n",
            "./notMNIST_large/J.pickle already present - Skipping pickling.\n",
            "./notMNIST_small/A.pickle already present - Skipping pickling.\n",
            "./notMNIST_small/B.pickle already present - Skipping pickling.\n",
            "./notMNIST_small/C.pickle already present - Skipping pickling.\n",
            "./notMNIST_small/D.pickle already present - Skipping pickling.\n",
            "./notMNIST_small/E.pickle already present - Skipping pickling.\n",
            "./notMNIST_small/F.pickle already present - Skipping pickling.\n",
            "./notMNIST_small/G.pickle already present - Skipping pickling.\n",
            "./notMNIST_small/H.pickle already present - Skipping pickling.\n",
            "./notMNIST_small/I.pickle already present - Skipping pickling.\n",
            "./notMNIST_small/J.pickle already present - Skipping pickling.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W4HNKrwLqe8v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "3969ff80-79d3-4da8-b3ed-857914ea5bfa"
      },
      "cell_type": "code",
      "source": [
        "def make_arrays(nb_rows, img_size):\n",
        "  if nb_rows:\n",
        "    dataset = np.ndarray((nb_rows, img_size, img_size), dtype=np.float32)\n",
        "    labels = np.ndarray(nb_rows, dtype=np.int32)\n",
        "  else:\n",
        "    dataset, labels = None, None\n",
        "  return dataset, labels\n",
        "\n",
        "def merge_datasets(pickle_files, train_size, valid_size=0):\n",
        "  num_classes = len(pickle_files)\n",
        "  valid_dataset, valid_labels = make_arrays(valid_size, image_size)\n",
        "  train_dataset, train_labels = make_arrays(train_size, image_size)\n",
        "  vsize_per_class = valid_size // num_classes\n",
        "  tsize_per_class = train_size // num_classes\n",
        "    \n",
        "  start_v, start_t = 0, 0\n",
        "  end_v, end_t = vsize_per_class, tsize_per_class\n",
        "  end_l = vsize_per_class+tsize_per_class\n",
        "  for label, pickle_file in enumerate(pickle_files):       \n",
        "    try:\n",
        "      with open(pickle_file, 'rb') as f:\n",
        "        letter_set = pickle.load(f)\n",
        "        # let's shuffle the letters to have random validation and training set\n",
        "        np.random.shuffle(letter_set)\n",
        "        if valid_dataset is not None:\n",
        "          valid_letter = letter_set[:vsize_per_class, :, :]\n",
        "          valid_dataset[start_v:end_v, :, :] = valid_letter\n",
        "          valid_labels[start_v:end_v] = label\n",
        "          start_v += vsize_per_class\n",
        "          end_v += vsize_per_class\n",
        "                    \n",
        "        train_letter = letter_set[vsize_per_class:end_l, :, :]\n",
        "        train_dataset[start_t:end_t, :, :] = train_letter\n",
        "        train_labels[start_t:end_t] = label\n",
        "        start_t += tsize_per_class\n",
        "        end_t += tsize_per_class\n",
        "    except Exception as e:\n",
        "      print('Unable to process data from', pickle_file, ':', e)\n",
        "      raise\n",
        "    \n",
        "  return valid_dataset, valid_labels, train_dataset, train_labels\n",
        "            \n",
        "            \n",
        "train_size = 200000\n",
        "valid_size = 10000\n",
        "test_size = 10000\n",
        "\n",
        "valid_dataset, valid_labels, train_dataset, train_labels = merge_datasets(\n",
        "  train_datasets, train_size, valid_size)\n",
        "_, _, test_dataset, test_labels = merge_datasets(test_datasets, test_size)\n",
        "\n",
        "print('Training:', train_dataset.shape, train_labels.shape)\n",
        "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
        "print('Testing:', test_dataset.shape, test_labels.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: (200000, 28, 28) (200000,)\n",
            "Validation: (10000, 28, 28) (10000,)\n",
            "Testing: (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wLfSUY8crQu4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def randomize(dataset, labels):\n",
        "  permutation = np.random.permutation(labels.shape[0])\n",
        "  shuffled_dataset = dataset[permutation,:,:]\n",
        "  shuffled_labels = labels[permutation]\n",
        "  return shuffled_dataset, shuffled_labels\n",
        "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
        "test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
        "valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TG3Mm1dBrXD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "5e32f0c7-931a-4540-bd7d-0a0bc8399d0d"
      },
      "cell_type": "code",
      "source": [
        "print(\"train_dataset.shape is\",train_dataset.shape)\n",
        "print(\"train_labels.shape is\",train_labels.shape)\n",
        "print(\"test_dataset.shape is\",test_dataset.shape)\n",
        "print(\"test_label.shape is\",test_labels.shape)\n",
        "print(\"valid_dataset.shape is\",valid_dataset.shape)\n",
        "print(\"valid_labels.shape is\",valid_labels.shape)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_dataset.shape is (200000, 28, 28)\n",
            "train_labels.shape is (200000,)\n",
            "test_dataset.shape is (10000, 28, 28)\n",
            "test_label.shape is (10000,)\n",
            "valid_dataset.shape is (10000, 28, 28)\n",
            "valid_labels.shape is (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T8noumgvrYG0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pickle_file = os.path.join(data_root, 'notMNIST.pickle')\n",
        "\n",
        "try:\n",
        "  f = open(pickle_file, 'wb')\n",
        "  save = {\n",
        "    'train_dataset': train_dataset,\n",
        "    'train_labels': train_labels,\n",
        "    'valid_dataset': valid_dataset,\n",
        "    'valid_labels': valid_labels,\n",
        "    'test_dataset': test_dataset,\n",
        "    'test_labels': test_labels,\n",
        "    }\n",
        "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
        "  f.close()\n",
        "except Exception as e:\n",
        "  print('Unable to save data to', pickle_file, ':', e)\n",
        "  raise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ILagZIAJr7U3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f15491c2-3738-448a-ef0f-e6f3105e71bf"
      },
      "cell_type": "code",
      "source": [
        "statinfo = os.stat(pickle_file)\n",
        "print('Compressed pickle size:', statinfo.st_size)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compressed pickle size: 690800506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bfFgSjeGsBIV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O6FrJAATpQg9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "hmqwRV9ys5SS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#读取.pickle的文件本数据中是保存的字母图片的矩阵的保存方式\n",
        "with open(\"notMNIST.pickle\",'rb') as f:\n",
        "  data=pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MkYA3K3XtAO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "307a5d65-63a0-4505-8a69-36bf908e2f3c"
      },
      "cell_type": "code",
      "source": [
        "data.keys()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['train_dataset', 'train_labels', 'valid_dataset', 'valid_labels', 'test_dataset', 'test_labels'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "Hmp3IO_7toXX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "9a8ab993-0b6a-42a8-db91-0aca2597cc67"
      },
      "cell_type": "code",
      "source": [
        "#数据的读取\n",
        "train_x,train_y=data[\"train_dataset\"],data[\"train_labels\"]\n",
        "print(\"train_x.shape is\",train_x.shape)\n",
        "print(\"train_y.shape is\",train_y.shape)\n",
        "valid_x,valid_y=data[\"valid_dataset\"],data[\"valid_labels\"]\n",
        "print(\"valid_x.shape is\",valid_x.shape)\n",
        "print(\"valid_y.shape is\",valid_y.shape)\n",
        "test_x,test_y=data[\"test_dataset\"],data[\"test_labels\"]\n",
        "print(\"test_x.shape is\",test_x.shape)\n",
        "print(\"test_y.shape is\",test_y.shape)\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_x.shape is (200000, 28, 28)\n",
            "train_y.shape is (200000,)\n",
            "valid_x.shape is (10000, 28, 28)\n",
            "valid_y.shape is (10000,)\n",
            "test_x.shape is (10000, 28, 28)\n",
            "test_y.shape is (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HidTwKeJ2q_2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_xx=[]\n",
        "for i in range(train_x.shape[0]):\n",
        "  train_xx.append(np.expand_dims(train_x[i],axis=-1))\n",
        "train_xx=np.array(train_xx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PmZRh6CC38iA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_xx=[]\n",
        "for i in range(valid_x.shape[0]):\n",
        "  valid_xx.append(np.expand_dims(valid_x[i],axis=-1))\n",
        "valid_xx=np.array(valid_xx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T7Pg7_3C49GN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_xx=[]\n",
        "for i in range(test_x.shape[0]):\n",
        "  test_xx.append(np.expand_dims(test_x[i],axis=-1))\n",
        "test_xx=np.array(test_xx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wvYzbodv_inK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_labe(train_yy):\n",
        "  temp=np.eye(10)\n",
        "  train_lab_y=[]\n",
        "  for i in range(train_yy.shape[0]):\n",
        "    if train_yy[i]==0:\n",
        "      train_lab_y.append(temp[0])\n",
        "    elif train_yy[i]==1:\n",
        "      train_lab_y.append(temp[1])\n",
        "    elif train_yy[i]==2:\n",
        "      train_lab_y.append(temp[2])\n",
        "    elif train_yy[i]==3:\n",
        "      train_lab_y.append(temp[3])\n",
        "    elif train_yy[i]==4:\n",
        "      train_lab_y.append(temp[4])\n",
        "    elif train_yy[i]==5:\n",
        "      train_lab_y.append(temp[5])\n",
        "    elif train_yy[i]==6:\n",
        "      train_lab_y.append(temp[6])\n",
        "    elif train_yy[i]==7:\n",
        "      train_lab_y.append(temp[7])\n",
        "    elif train_yy[i]==8:\n",
        "      train_lab_y.append(temp[8])\n",
        "    elif train_yy[i]==9:\n",
        "      train_lab_y.append(temp[9])\n",
        "  \n",
        "  train_lab_y=np.array(train_lab_y)\n",
        "  return train_lab_y\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VjpZlRua_jIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_yy=make_labe(train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YFOIy2j8Dp6G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_yy=make_labe(test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Nq84Lmfzr9K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WINYdHl-5JoR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "0f028cc5-e6e1-468b-dc7e-079b0d659012"
      },
      "cell_type": "code",
      "source": [
        "print(\"train_xx.shape is\",train_xx.shape)\n",
        "print(\"train_yy.shape is\",train_yy.shape)\n",
        "print(\"valid_xx.shape is\",valid_xx.shape)\n",
        "print(\"valid_y.shape is\",valid_y.shape)\n",
        "print(\"test_xx.shape is\",test_xx.shape)\n",
        "print(\"test_yy.shape is\",test_yy.shape)\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_xx.shape is (200000, 28, 28, 1)\n",
            "train_yy.shape is (200000, 10)\n",
            "valid_xx.shape is (10000, 28, 28, 1)\n",
            "valid_y.shape is (10000,)\n",
            "test_xx.shape is (10000, 28, 28, 1)\n",
            "test_yy.shape is (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uJkp7HVO5U2A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "y5GdKzw_0quR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def weight(shape):\n",
        "  init=tf.random_normal(shape,stddev=0.1)\n",
        "  return tf.Variable(init)\n",
        "def biase(shape):\n",
        "  init=tf.random_normal(shape,stddev=0.1)\n",
        "  return tf.Variable(init)\n",
        "def conv2(x,w):\n",
        "  return tf.nn.conv2d(x,w,strides=[1,1,1,1],padding=\"SAME\")\n",
        "def max_pool(x):\n",
        "  return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
        "def dropout(x,keep):\n",
        "  return tf.nn.dropout(x,keep)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CTrzF7ax1Tot",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x=tf.placeholder(tf.float32,[None,28,28,1])\n",
        "y=tf.placeholder(tf.float32,[None,10])\n",
        "keep1=tf.placeholder(tf.float32)\n",
        "keep10=tf.placeholder(tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QNIVqT7g17if",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f774eb1-6a36-46d6-ce90-61e86d856935"
      },
      "cell_type": "code",
      "source": [
        "#the first layer\n",
        "w1=weight([4,4,1,32])\n",
        "b1=biase([32])\n",
        "wb1=tf.nn.relu(conv2(x,w1)+b1)\n",
        "pool1=max_pool(wb1)\n",
        "drop1=dropout(pool1,keep1)\n",
        "print(\"drop1.shape is\",drop1.shape)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drop1.shape is (?, 14, 14, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KR9_R0T12MGO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63465daf-88de-49c1-b973-b7c6b97adb45"
      },
      "cell_type": "code",
      "source": [
        "#the second layer\n",
        "w2=weight([4,4,32,512])\n",
        "b2=biase([512])\n",
        "wb2=tf.nn.relu(conv2(drop1,w2)+b2)\n",
        "pool2=max_pool(wb2)\n",
        "drop2=dropout(pool2,keep1)\n",
        "print(\"drop2.shape is\",drop2.shape)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drop2.shape is (?, 7, 7, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "trwWiPwJ5vZG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ef80d0b-a05e-48c4-bae0-5538062115da"
      },
      "cell_type": "code",
      "source": [
        "#full layer\n",
        "wf=weight([7*7*512,128])\n",
        "bf=biase([128])\n",
        "drop2_flat=tf.reshape(drop2,[-1,7*7*512])\n",
        "wbf=tf.nn.relu(tf.matmul(drop2_flat,wf)+bf)\n",
        "dropf=dropout(wbf,keep10)\n",
        "print(\"dropf.shape\",dropf.shape)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dropf.shape (?, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8eN64mgj7S12",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d468c18-7ec3-4380-ddd4-8dcb5902cab1"
      },
      "cell_type": "code",
      "source": [
        "#out layer\n",
        "wout=weight([128,10])\n",
        "bout=biase([10])\n",
        "out=tf.matmul(dropf,wout)+bout\n",
        "print(\"out.shape is\",out.shape)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "out.shape is (?, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RPWC8pZQ7t3O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cross_entropy=cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=out,labels=y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KZMA3xE07vka",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train=tf.train.AdamOptimizer(0.001).minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BF_tPp998SAh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "accuracy=tf.reduce_mean(tf.cast(tf.equal(tf.argmax(out,1),tf.argmax(y,1)),tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9mmQLsHd8Wsa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "525f352b-2e1a-4f76-9455-140798dde016"
      },
      "cell_type": "code",
      "source": [
        "batch_size=100\n",
        "num_batch=train_xx.shape[0]//batch_size\n",
        "print(num_batch)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yYoRyYf08c1t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "1af81878-6adf-4ada-da1d-44c607a17960"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for j in range(2):\n",
        "    for i in range(num_batch):\n",
        "      batch_x=train_xx[i*batch_size:(i+1)*batch_size]\n",
        "      batch_y=train_yy[i*batch_size:(i+1)*batch_size]\n",
        "      _,loss=sess.run([train,cross_entropy],feed_dict={x:batch_x,y:batch_y,keep1:0.5,keep10:0.8})\n",
        "      if i%100==0:\n",
        "        print(\"the loss is===>\",loss)\n",
        "    if (j+1)*batch_size%100==0:\n",
        "      print(\"[++++++++++++++++++++++++++++++++++++++++++++++++++]\")\n",
        "      acc = accuracy.eval({x:test_xx, y:test_yy, keep1:1.0, keep10:1.0})\n",
        "      print(\"the acc is \",acc)\n",
        "      print(\"[++++++++++++++++++++++++++++++++++++++++++++++++++]\")\n",
        "            \n",
        "      "
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the loss is===> 15.349357\n",
            "the loss is===> 1.731937\n",
            "the loss is===> 1.0850391\n",
            "the loss is===> 0.9187096\n",
            "the loss is===> 1.1825658\n",
            "the loss is===> 0.64177096\n",
            "the loss is===> 0.6987003\n",
            "the loss is===> 0.4761429\n",
            "the loss is===> 0.57452387\n",
            "the loss is===> 0.79943544\n",
            "the loss is===> 0.5283295\n",
            "the loss is===> 0.46956563\n",
            "the loss is===> 0.5257047\n",
            "the loss is===> 0.38737392\n",
            "the loss is===> 0.56285423\n",
            "the loss is===> 0.4723314\n",
            "the loss is===> 0.5431472\n",
            "the loss is===> 0.48570648\n",
            "the loss is===> 0.43629703\n",
            "the loss is===> 0.71163446\n",
            "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
            "the acc is  0.9408\n",
            "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
            "the loss is===> 0.46446407\n",
            "the loss is===> 0.5771772\n",
            "the loss is===> 0.42424697\n",
            "the loss is===> 0.5101562\n",
            "the loss is===> 0.71990913\n",
            "the loss is===> 0.33665973\n",
            "the loss is===> 0.37915444\n",
            "the loss is===> 0.33808655\n",
            "the loss is===> 0.3828899\n",
            "the loss is===> 0.67326975\n",
            "the loss is===> 0.30043292\n",
            "the loss is===> 0.34873176\n",
            "the loss is===> 0.40842855\n",
            "the loss is===> 0.318807\n",
            "the loss is===> 0.45521706\n",
            "the loss is===> 0.40151933\n",
            "the loss is===> 0.48301327\n",
            "the loss is===> 0.54695785\n",
            "the loss is===> 0.31888884\n",
            "the loss is===> 0.55327034\n",
            "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
            "the acc is  0.9525\n",
            "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_G-aTkf4-UjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7bc22ae2-11e0-4997-ea07-bd81f6b5e05b"
      },
      "cell_type": "code",
      "source": [
        "train_xx.shape"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "metadata": {
        "id": "JsOn1GaY-WHe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ce07052-85e4-449e-b8dd-f2065dc6532d"
      },
      "cell_type": "code",
      "source": [
        "train_yy.shape"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "metadata": {
        "id": "AZI8Yd52B9fg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30b7f68d-fed0-442e-e929-45cc3392d448"
      },
      "cell_type": "code",
      "source": [
        "test_xx.shape"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "metadata": {
        "id": "_k6azDMFCuZo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a259d43-f45e-4f08-e1a1-7d90ec53662e"
      },
      "cell_type": "code",
      "source": [
        "test_yy.shape"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "metadata": {
        "id": "_EQIjGxoDAxI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "417e2746-c843-46f1-9554-9dec58ea15d3"
      },
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  number=input(\"请输入一个三位的整数\")\n",
        "  try:\n",
        "    eval(number)\n",
        "  except:\n",
        "    print(\"输入的数字不合法\")\n",
        "    break\n",
        "  if len(number) !=3:\n",
        "    print(\"输入的数字不是三位数请继续\")\n",
        "    continue\n",
        "  a=[]\n",
        "  for per in number:\n",
        "    a.append(pow(int(per),3))\n",
        "  Sum=sum(a)\n",
        "  if Sum==int(number):\n",
        "    print(\"%d 是一个水仙花数!\"%(int(number)))\n",
        "  else:\n",
        "    print(\"%d不是水仙花数\"%(int(number)))\n",
        "  "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "请输入一个三位的整数153\n",
            "153 是一个水仙花数!\n",
            "请输入一个三位的整数111\n",
            "111不是水仙花数\n",
            "请输入一个三位的整数123\n",
            "123不是水仙花数\n",
            "请输入一个三位的整数111\n",
            "111不是水仙花数\n",
            "请输入一个三位的整数asd\n",
            "输入的数字不合法\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jt32g065rN0i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "cff4daaa-4943-4172-fc82-c1d516fcb67b"
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "rand=random.randint(1,5)\n",
        "counter=0\n",
        "while True:\n",
        "  gust=input(\"请输入1～5的任意的一个数!\")\n",
        "  try:\n",
        "    eval(gust)\n",
        "  except:\n",
        "    print(\"数字不合法请重新输入！\")\n",
        "    continue\n",
        "  if int(gust)<1 or int(gust)>5:\n",
        "    print(\"输入的数字超出范围请重新输入\")\n",
        "    continue\n",
        "  if int(gust)==rand:\n",
        "    print(\"恭喜了才对了！\")\n",
        "    break\n",
        "  else:\n",
        "    if int(gust)<rand:\n",
        "      print(\"猜的数字小了!\")\n",
        "    else:\n",
        "      print(\"猜的数字大了!\")\n",
        "  "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "请输入1～5的任意的一个数!4\n",
            "猜的数字大了!\n",
            "请输入1～5的任意的一个数!2\n",
            "猜的数字小了!\n",
            "请输入1～5的任意的一个数!3\n",
            "恭喜了才对了！\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZSttIJI3v3Cq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}