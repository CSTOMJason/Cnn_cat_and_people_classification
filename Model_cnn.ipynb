{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import dlib\n",
    "import random \n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_path=\"cat_pic/\"#猫图片的位置\n",
    "face_path=\"face_pic/\"#人脸图片的位置\n",
    "imgs=[]#存放图片(None,64,64,3)\n",
    "labs=[]\n",
    "#图片的读取和统一shape(64,64,3)\n",
    "def read_data(path):\n",
    "    for per in os.listdir(path):\n",
    "        img_per=cv2.imread(path+per)\n",
    "        imgs.append(img_per)\n",
    "        labs.append(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data(cat_path)\n",
    "read_data(face_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgs' length is  2000\n",
      "labs' length is  2000\n",
      "[0 1]\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "#数据的处理和制作标签数据\n",
    "print(\"imgs' length is \",len(imgs))\n",
    "print(\"labs' length is \",len(labs))\n",
    "labs=np.array([[0,1] if lab==\"cat_pic/\" else [1,0] for lab in labs])\n",
    "imgs=np.array(imgs)\n",
    "labs=np.array(labs)\n",
    "print(labs[0])\n",
    "print(labs[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape is (1600, 64, 64, 3)\n",
      "train_y.shape is (1600, 2)\n",
      "test_x.shape is (400, 64, 64, 3)\n",
      "test_y.shape is (400, 2)\n"
     ]
    }
   ],
   "source": [
    "train_x,test_x,train_y,test_y=train_test_split(imgs,labs,test_size=0.2)#数据的划分\n",
    "print(\"train_x.shape is\",train_x.shape)\n",
    "print(\"train_y.shape is\",train_y.shape)\n",
    "print(\"test_x.shape is\",test_x.shape)\n",
    "print(\"test_y.shape is\",test_y.shape)\n",
    "#数据转化为0～1之间的数求概念需求\n",
    "train_x=train_x/255.0\n",
    "test_x=test_x/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x Tensor(\"x:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "y Tensor(\"y:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#占位符\n",
    "x=tf.placeholder(tf.float32,[None,64,64,3],name=\"x\")\n",
    "y=tf.placeholder(tf.float32,[None,2],name=\"y\")\n",
    "keep_prob_1=tf.placeholder(tf.float32)\n",
    "keep_prob_10=tf.placeholder(tf.float32)\n",
    "print(\"x\",x)\n",
    "print(\"y\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义网络的函数\n",
    "def weight(shape):\n",
    "    init=tf.random_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(init)\n",
    "def biase(shape):\n",
    "    init=tf.random_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(init)\n",
    "def conv2(x,w):\n",
    "    return tf.nn.conv2d(x,w,strides=[1,1,1,1],padding=\"SAME\")\n",
    "def max_pool(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "def dropout(x,keep):\n",
    "    return tf.nn.dropout(x,keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop1.shape (?, 32, 32, 32)\n",
      "drops.shape  (?, 16, 16, 64)\n",
      "dropf.shape  (?, 512)\n",
      "out.shape  (?, 2)\n",
      "x is Tensor(\"x:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "y is Tensor(\"y:0\", shape=(?, 2), dtype=float32)\n",
      "out is Tensor(\"Add:0\", shape=(?, 2), dtype=float32)\n",
      "cross_entropy.shape  ()\n"
     ]
    }
   ],
   "source": [
    "#定义网络\n",
    "#第一层卷积\n",
    "w1=weight([4,4,3,32])\n",
    "b1=biase([32])\n",
    "wb1=tf.nn.relu(conv2(x,w1)+b1)\n",
    "pool1=max_pool(wb1)\n",
    "drop1=dropout(pool1,keep_prob_1)\n",
    "print(\"drop1.shape\",drop1.shape)\n",
    "#第二层卷积\n",
    "w2=weight([3,3,32,64])\n",
    "b2=biase([64])\n",
    "wb2=tf.nn.relu(conv2(drop1,w2)+b2)\n",
    "pool2=max_pool(wb2)\n",
    "drop2=dropout(pool2,keep_prob_1)\n",
    "print(\"drops.shape \",drop2.shape)\n",
    "W3 = weight([3,3,64,64])\n",
    "b3 = biase([64])\n",
    "conv3 = tf.nn.relu(conv2(drop2, W3) + b3)\n",
    "pool3 = max_pool(conv3)\n",
    "drop3 = dropout(pool3, keep_prob_1)\n",
    "#全连接层\n",
    "Wf = weight([8*16*32, 512])\n",
    "bf = biase([512])\n",
    "drop3_flat = tf.reshape(drop3, [-1, 8*16*32])\n",
    "dense = tf.nn.relu(tf.matmul(drop3_flat, Wf) + bf)\n",
    "dropf = dropout(dense, keep_prob_10)\n",
    "print(\"dropf.shape \",dropf.shape)\n",
    "\n",
    "#输出层\n",
    "Wout = weight([512,2])\n",
    "bout = weight([2])\n",
    "#out = tf.matmul(dropf, Wout) + bout\n",
    "out = tf.add(tf.matmul(dropf, Wout), bout)\n",
    "print(\"out.shape \",out.shape)\n",
    "print(\"x is\",x)\n",
    "print(\"y is\",y)\n",
    "print(\"out is\",out)\n",
    "cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=out,labels=y))\n",
    "print(\"cross_entropy.shape \",cross_entropy.shape )\n",
    "train=tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "accuracy=tf.reduce_mean(tf.cast(tf.equal(tf.argmax(out,1),tf.argmax(y,1)),tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is  30.99741\n",
      "the loss is  88.64633\n",
      "the loss is  37.159946\n",
      "the loss is  16.144459\n",
      "the loss is  21.511425\n",
      "the loss is  29.65139\n",
      "the loss is  20.997042\n",
      "the loss is  15.242458\n",
      "the loss is  7.2472205\n",
      "the loss is  5.121741\n",
      "the loss is  6.711995\n",
      "the loss is  8.18066\n",
      "the loss is  7.4022427\n",
      "the loss is  7.5028114\n",
      "the loss is  5.601233\n",
      "the loss is  4.197829\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
      "the acc is  0.5325\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
      "the loss is  2.8936918\n",
      "the loss is  2.31391\n",
      "the loss is  2.7194746\n",
      "the loss is  2.2538416\n",
      "the loss is  2.069006\n",
      "the loss is  2.9661994\n",
      "the loss is  2.376247\n",
      "the loss is  2.8522632\n",
      "the loss is  1.5604061\n",
      "the loss is  2.0107315\n",
      "the loss is  2.0855346\n",
      "the loss is  1.5518913\n",
      "the loss is  1.329775\n",
      "the loss is  1.3423976\n",
      "the loss is  1.3012908\n",
      "the loss is  1.4373926\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
      "the acc is  0.575\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
      "the loss is  1.0097322\n",
      "the loss is  1.3759129\n",
      "the loss is  1.2719783\n",
      "the loss is  1.4957272\n",
      "the loss is  1.364751\n",
      "the loss is  1.0201766\n",
      "the loss is  1.296494\n",
      "the loss is  1.0713332\n",
      "the loss is  1.0058947\n",
      "the loss is  0.8479639\n",
      "the loss is  0.716216\n",
      "the loss is  0.9883928\n",
      "the loss is  1.0188781\n",
      "the loss is  0.8114043\n",
      "the loss is  0.9213859\n",
      "the loss is  0.9283879\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
      "the acc is  0.4775\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
      "the loss is  0.94106656\n",
      "the loss is  1.0824347\n",
      "the loss is  0.99442506\n",
      "the loss is  0.8388563\n",
      "the loss is  0.8034245\n",
      "the loss is  0.82010955\n",
      "the loss is  0.8320293\n",
      "the loss is  0.73679906\n",
      "the loss is  0.7186679\n",
      "the loss is  0.8029851\n",
      "the loss is  0.6042645\n",
      "the loss is  0.75639725\n",
      "the loss is  0.63127977\n",
      "the loss is  0.786193\n",
      "the loss is  0.932714\n",
      "the loss is  0.4997992\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
      "the acc is  0.5325\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
      "the loss is  0.6862566\n",
      "the loss is  0.72756547\n",
      "the loss is  0.80596876\n",
      "the loss is  0.72763205\n",
      "the loss is  0.678571\n",
      "the loss is  0.71071136\n",
      "the loss is  0.85784507\n",
      "the loss is  0.6313333\n",
      "the loss is  0.57870084\n",
      "the loss is  0.57055\n",
      "the loss is  0.4856759\n",
      "the loss is  0.55664873\n",
      "the loss is  0.5922675\n",
      "the loss is  0.6118777\n",
      "the loss is  0.57294637\n",
      "the loss is  0.6810384\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
      "the acc is  0.6425\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
      "the loss is  0.5502164\n",
      "the loss is  0.6248272\n",
      "the loss is  0.43390587\n",
      "the loss is  0.44875085\n",
      "the loss is  0.48763996\n",
      "the loss is  0.4936202\n",
      "the loss is  0.54462135\n",
      "the loss is  0.41375673\n",
      "the loss is  0.43732464\n",
      "the loss is  0.34437618\n",
      "the loss is  0.47360143\n",
      "the loss is  0.36788616\n",
      "the loss is  0.39029706\n",
      "the loss is  0.39615968\n",
      "the loss is  0.26809713\n",
      "the loss is  0.34255886\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
      "the acc is  0.76\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
      "the loss is  0.37871808\n",
      "the loss is  0.28181148\n",
      "the loss is  0.335553\n",
      "the loss is  0.33839244\n",
      "the loss is  0.375696\n",
      "the loss is  0.35862005\n",
      "the loss is  0.34103653\n",
      "the loss is  0.34693894\n",
      "the loss is  0.3082566\n",
      "the loss is  0.24007772\n",
      "the loss is  0.2741713\n",
      "the loss is  0.2327022\n",
      "the loss is  0.3015479\n",
      "the loss is  0.26248938\n",
      "the loss is  0.22589472\n",
      "the loss is  0.19990265\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
      "the acc is  0.9125\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
      "the loss is  0.27901486\n",
      "the loss is  0.23959836\n",
      "the loss is  0.16640498\n",
      "the loss is  0.24624626\n",
      "the loss is  0.14116424\n",
      "the loss is  0.17605823\n",
      "the loss is  0.1899333\n",
      "the loss is  0.19627024\n",
      "the loss is  0.13331878\n",
      "the loss is  0.16426915\n",
      "the loss is  0.27789706\n",
      "the loss is  0.25344312\n",
      "the loss is  0.307831\n",
      "the loss is  0.16172776\n",
      "the loss is  0.21763597\n",
      "the loss is  0.16589054\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
      "the acc is  0.885\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
      "the loss is  0.33848122\n",
      "the loss is  0.27709594\n",
      "the loss is  0.05958606\n",
      "the loss is  0.21909493\n",
      "the loss is  0.152609\n",
      "the loss is  0.15783525\n",
      "the loss is  0.18743935\n",
      "the loss is  0.24105823\n",
      "the loss is  0.08573233\n",
      "the loss is  0.21940996\n",
      "the loss is  0.22327662\n",
      "the loss is  0.14819889\n",
      "the loss is  0.23721668\n",
      "the loss is  0.14030959\n",
      "the loss is  0.115989424\n",
      "the loss is  0.06796735\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
      "the acc is  0.935\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
      "the loss is  0.21980639\n",
      "the loss is  0.120744474\n",
      "the loss is  0.068815306\n",
      "the loss is  0.114541456\n",
      "the loss is  0.14616764\n",
      "the loss is  0.106199235\n",
      "the loss is  0.110456\n",
      "the loss is  0.17226051\n",
      "the loss is  0.10061207\n",
      "the loss is  0.085842036\n",
      "the loss is  0.15086946\n",
      "the loss is  0.17729594\n",
      "the loss is  0.22314765\n",
      "the loss is  0.14396009\n",
      "the loss is  0.07809205\n",
      "the loss is  0.15209037\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n",
      "the acc is  0.935\n",
      "[++++++++++++++++++++++++++++++++++++++++++++++++++]\n"
     ]
    }
   ],
   "source": [
    "batch_size=100\n",
    "num_batch=train_x.shape[0]#batch_szie\n",
    "#saver = tf.train.Saver()#模型的保存\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for j in range(10):\n",
    "        for i in range(num_batch):\n",
    "            batch_x=train_x[i*batch_size:(i+1)*batch_size]\n",
    "            batch_y=train_y[i*batch_size:(i+1)*batch_size]\n",
    "            _,loss=sess.run([train,cross_entropy],\n",
    "                               feed_dict={x:batch_x,y:batch_y,keep_prob_1:0.5,keep_prob_10:0.75})\n",
    "            print(\"the loss is \",loss)\n",
    "        if (j+1)*batch_size%50==0:\n",
    "            print(\"[++++++++++++++++++++++++++++++++++++++++++++++++++]\")\n",
    "            acc = accuracy.eval({x:test_x, y:test_y, keep_prob_1:1.0, keep_prob_10:1.0})\n",
    "            print(\"the acc is \",acc)\n",
    "            print(\"[++++++++++++++++++++++++++++++++++++++++++++++++++]\")\n",
    "            \n",
    "    #saver.save(sess, \"./model/model.ckpt\")#保存模型到当前目录下的 model/model.ckpt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    saver=tf.train.import_meta_graph(\"./model/model.ckpt.meta\")#加载模型\n",
    "    graph=tf.get_default_graph()\n",
    "    x=graph.get_tensor_by_name(\"x:0\")#获取模型中的placeholder括号内为placeholder的名字上面打出来的请参考\n",
    "    y=graph.get_tensor_by_name(\"y:0\")\n",
    "    keep1=graph.get_tensor_by_name(\"Placeholder:0\")\n",
    "    keep10=graph.get_tensor_by_name(\"Placeholder_1:0\")\n",
    "    prediction=graph.get_tensor_by_name(\"Add:0\")\n",
    "    img=cv2.imread(\"101.jpg\")#测试的数据\n",
    "    test_img=cv2.resize(img,(64,64))\n",
    "    test_img=test_img/255.0\n",
    "    test_lab=np.array([0,1])\n",
    "    test_img=np.expand_dims(test_img,axis=0)#扩展一个维度与输入匹配\n",
    "    test_lab=np.expand_dims(test_lab,axis=0)#扩展一个维度与输入匹配\n",
    "    print(\"test_img.shape is \",test_img.shape)\n",
    "    print(\"test_lab.shape is\",test_lab.shape)\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess,\"./model/model.ckpt\")\n",
    "        print(sess.run(prediction,feed_dict={x:test_img,y:test_lab,keep1:1.0,keep10:1.0}))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
